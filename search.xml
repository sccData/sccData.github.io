<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Numpy基础(二)]]></title>
    <url>%2F2018%2F09%2F24%2FNumpy%E5%9F%BA%E7%A1%80-%E4%BA%8C%2F</url>
    <content type="text"><![CDATA[通用函数 array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) array([0. , 1. , 1.41421356, 1.73205081, 2. , 2.23606798, 2.44948974, 2.64575131, 2.82842712, 3. ]) array([1.00000000e+00, 2.71828183e+00, 7.38905610e+00, 2.00855369e+01, 5.45981500e+01, 1.48413159e+02, 4.03428793e+02, 1.09663316e+03, 2.98095799e+03, 8.10308393e+03]) 将x和y中元素的最大值计算出来 array([-0.11304338, -0.76289493, 0.43239433, -0.43824016, -0.20903412, 0.71434066, -0.06336307, 0.39328985]) array([-1.33963444, -1.10799164, 0.47448542, -1.1580294 , -1.03593423, -0.10586832, 1.1356464 , -0.38837099]) array([-0.11304338, -0.76289493, 0.47448542, -0.43824016, -0.20903412, 0.71434066, 1.1356464 , 0.39328985]) 返回一个浮点值数组的小数部分和整数部分 array([-2.75671329, -8.76996314, 1.69028983, 4.88101888, 0.44040745, -0.71775915, 2.44074476]) array([ 0.78950202, 0.54393575, 0.07643697, -0.55350828, 0.67900656, -0.96970101, -0.66190604]) array([ 1., 0., 1., -0., 9., -2., -3.]) array([ 1.78950202, 0.54393575, 1.07643697, -0.55350828, 9.67900656, -2.96970101, -3.66190604]) /home/scc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in sqrt &quot;&quot;&quot;Entry point for launching an IPython kernel. array([1.3377227 , 0.73752 , 1.0375148 , nan, 3.11111018, nan, nan]) /home/scc/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in sqrt &quot;&quot;&quot;Entry point for launching an IPython kernel. array([1.3377227 , 0.73752 , 1.0375148 , nan, 3.11111018, nan, nan]) array([1.3377227 , 0.73752 , 1.0375148 , nan, 3.11111018, nan, nan]) 使用数组进行面向数组编程 array([-5.0000000e+00, -4.9900000e+00, -4.9800000e+00, -4.9700000e+00, -4.9600000e+00, -4.9500000e+00, -4.9400000e+00, -4.9300000e+00, -4.9200000e+00, -4.9100000e+00, -4.9000000e+00, -4.8900000e+00, -4.8800000e+00, -4.8700000e+00, -4.8600000e+00, -4.8500000e+00, -4.8400000e+00, -4.8300000e+00, -4.8200000e+00, -4.8100000e+00, -4.8000000e+00, -4.7900000e+00, -4.7800000e+00, -4.7700000e+00, -4.7600000e+00, -4.7500000e+00, -4.7400000e+00, -4.7300000e+00, -4.7200000e+00, -4.7100000e+00, -4.7000000e+00, -4.6900000e+00, -4.6800000e+00, -4.6700000e+00, -4.6600000e+00, -4.6500000e+00, -4.6400000e+00, -4.6300000e+00, -4.6200000e+00, -4.6100000e+00, -4.6000000e+00, -4.5900000e+00, -4.5800000e+00, -4.5700000e+00, -4.5600000e+00, -4.5500000e+00, -4.5400000e+00, -4.5300000e+00, -4.5200000e+00, -4.5100000e+00, -4.5000000e+00, -4.4900000e+00, -4.4800000e+00, -4.4700000e+00, -4.4600000e+00, -4.4500000e+00, -4.4400000e+00, -4.4300000e+00, -4.4200000e+00, -4.4100000e+00, -4.4000000e+00, -4.3900000e+00, -4.3800000e+00, -4.3700000e+00, -4.3600000e+00, -4.3500000e+00, -4.3400000e+00, -4.3300000e+00, -4.3200000e+00, -4.3100000e+00, -4.3000000e+00, -4.2900000e+00, -4.2800000e+00, -4.2700000e+00, -4.2600000e+00, -4.2500000e+00, -4.2400000e+00, -4.2300000e+00, -4.2200000e+00, -4.2100000e+00, -4.2000000e+00, -4.1900000e+00, -4.1800000e+00, -4.1700000e+00, -4.1600000e+00, -4.1500000e+00, -4.1400000e+00, -4.1300000e+00, -4.1200000e+00, -4.1100000e+00, -4.1000000e+00, -4.0900000e+00, -4.0800000e+00, -4.0700000e+00, -4.0600000e+00, -4.0500000e+00, -4.0400000e+00, -4.0300000e+00, -4.0200000e+00, -4.0100000e+00, -4.0000000e+00, -3.9900000e+00, -3.9800000e+00, -3.9700000e+00, -3.9600000e+00, -3.9500000e+00, -3.9400000e+00, -3.9300000e+00, -3.9200000e+00, -3.9100000e+00, -3.9000000e+00, -3.8900000e+00, -3.8800000e+00, -3.8700000e+00, -3.8600000e+00, -3.8500000e+00, -3.8400000e+00, -3.8300000e+00, -3.8200000e+00, -3.8100000e+00, -3.8000000e+00, -3.7900000e+00, -3.7800000e+00, -3.7700000e+00, -3.7600000e+00, -3.7500000e+00, -3.7400000e+00, -3.7300000e+00, -3.7200000e+00, -3.7100000e+00, -3.7000000e+00, -3.6900000e+00, -3.6800000e+00, -3.6700000e+00, -3.6600000e+00, -3.6500000e+00, -3.6400000e+00, -3.6300000e+00, -3.6200000e+00, -3.6100000e+00, -3.6000000e+00, -3.5900000e+00, -3.5800000e+00, -3.5700000e+00, -3.5600000e+00, -3.5500000e+00, -3.5400000e+00, -3.5300000e+00, -3.5200000e+00, -3.5100000e+00, -3.5000000e+00, -3.4900000e+00, -3.4800000e+00, -3.4700000e+00, -3.4600000e+00, -3.4500000e+00, -3.4400000e+00, -3.4300000e+00, -3.4200000e+00, -3.4100000e+00, -3.4000000e+00, -3.3900000e+00, -3.3800000e+00, -3.3700000e+00, -3.3600000e+00, -3.3500000e+00, -3.3400000e+00, -3.3300000e+00, -3.3200000e+00, -3.3100000e+00, -3.3000000e+00, -3.2900000e+00, -3.2800000e+00, -3.2700000e+00, -3.2600000e+00, -3.2500000e+00, -3.2400000e+00, -3.2300000e+00, -3.2200000e+00, -3.2100000e+00, -3.2000000e+00, -3.1900000e+00, -3.1800000e+00, -3.1700000e+00, -3.1600000e+00, -3.1500000e+00, -3.1400000e+00, -3.1300000e+00, -3.1200000e+00, -3.1100000e+00, -3.1000000e+00, -3.0900000e+00, -3.0800000e+00, -3.0700000e+00, -3.0600000e+00, -3.0500000e+00, -3.0400000e+00, -3.0300000e+00, -3.0200000e+00, -3.0100000e+00, -3.0000000e+00, -2.9900000e+00, -2.9800000e+00, -2.9700000e+00, -2.9600000e+00, -2.9500000e+00, -2.9400000e+00, -2.9300000e+00, -2.9200000e+00, -2.9100000e+00, -2.9000000e+00, -2.8900000e+00, -2.8800000e+00, -2.8700000e+00, -2.8600000e+00, -2.8500000e+00, -2.8400000e+00, -2.8300000e+00, -2.8200000e+00, -2.8100000e+00, -2.8000000e+00, -2.7900000e+00, -2.7800000e+00, -2.7700000e+00, -2.7600000e+00, -2.7500000e+00, -2.7400000e+00, -2.7300000e+00, -2.7200000e+00, -2.7100000e+00, -2.7000000e+00, -2.6900000e+00, -2.6800000e+00, -2.6700000e+00, -2.6600000e+00, -2.6500000e+00, -2.6400000e+00, -2.6300000e+00, -2.6200000e+00, -2.6100000e+00, -2.6000000e+00, -2.5900000e+00, -2.5800000e+00, -2.5700000e+00, -2.5600000e+00, -2.5500000e+00, -2.5400000e+00, -2.5300000e+00, -2.5200000e+00, -2.5100000e+00, -2.5000000e+00, -2.4900000e+00, -2.4800000e+00, -2.4700000e+00, -2.4600000e+00, -2.4500000e+00, -2.4400000e+00, -2.4300000e+00, -2.4200000e+00, -2.4100000e+00, -2.4000000e+00, -2.3900000e+00, -2.3800000e+00, -2.3700000e+00, -2.3600000e+00, -2.3500000e+00, -2.3400000e+00, -2.3300000e+00, -2.3200000e+00, -2.3100000e+00, -2.3000000e+00, -2.2900000e+00, -2.2800000e+00, -2.2700000e+00, -2.2600000e+00, -2.2500000e+00, -2.2400000e+00, -2.2300000e+00, -2.2200000e+00, -2.2100000e+00, -2.2000000e+00, -2.1900000e+00, -2.1800000e+00, -2.1700000e+00, -2.1600000e+00, -2.1500000e+00, -2.1400000e+00, -2.1300000e+00, -2.1200000e+00, -2.1100000e+00, -2.1000000e+00, -2.0900000e+00, -2.0800000e+00, -2.0700000e+00, -2.0600000e+00, -2.0500000e+00, -2.0400000e+00, -2.0300000e+00, -2.0200000e+00, -2.0100000e+00, -2.0000000e+00, -1.9900000e+00, -1.9800000e+00, -1.9700000e+00, -1.9600000e+00, -1.9500000e+00, -1.9400000e+00, -1.9300000e+00, -1.9200000e+00, -1.9100000e+00, -1.9000000e+00, -1.8900000e+00, -1.8800000e+00, -1.8700000e+00, -1.8600000e+00, -1.8500000e+00, -1.8400000e+00, -1.8300000e+00, -1.8200000e+00, -1.8100000e+00, -1.8000000e+00, -1.7900000e+00, -1.7800000e+00, -1.7700000e+00, -1.7600000e+00, -1.7500000e+00, -1.7400000e+00, -1.7300000e+00, -1.7200000e+00, -1.7100000e+00, -1.7000000e+00, -1.6900000e+00, -1.6800000e+00, -1.6700000e+00, -1.6600000e+00, -1.6500000e+00, -1.6400000e+00, -1.6300000e+00, -1.6200000e+00, -1.6100000e+00, -1.6000000e+00, -1.5900000e+00, -1.5800000e+00, -1.5700000e+00, -1.5600000e+00, -1.5500000e+00, -1.5400000e+00, -1.5300000e+00, -1.5200000e+00, -1.5100000e+00, -1.5000000e+00, -1.4900000e+00, -1.4800000e+00, -1.4700000e+00, -1.4600000e+00, -1.4500000e+00, -1.4400000e+00, -1.4300000e+00, -1.4200000e+00, -1.4100000e+00, -1.4000000e+00, -1.3900000e+00, -1.3800000e+00, -1.3700000e+00, -1.3600000e+00, -1.3500000e+00, -1.3400000e+00, -1.3300000e+00, -1.3200000e+00, -1.3100000e+00, -1.3000000e+00, -1.2900000e+00, -1.2800000e+00, -1.2700000e+00, -1.2600000e+00, -1.2500000e+00, -1.2400000e+00, -1.2300000e+00, -1.2200000e+00, -1.2100000e+00, -1.2000000e+00, -1.1900000e+00, -1.1800000e+00, -1.1700000e+00, -1.1600000e+00, -1.1500000e+00, -1.1400000e+00, -1.1300000e+00, -1.1200000e+00, -1.1100000e+00, -1.1000000e+00, -1.0900000e+00, -1.0800000e+00, -1.0700000e+00, -1.0600000e+00, -1.0500000e+00, -1.0400000e+00, -1.0300000e+00, -1.0200000e+00, -1.0100000e+00, -1.0000000e+00, -9.9000000e-01, -9.8000000e-01, -9.7000000e-01, -9.6000000e-01, -9.5000000e-01, -9.4000000e-01, -9.3000000e-01, -9.2000000e-01, -9.1000000e-01, -9.0000000e-01, -8.9000000e-01, -8.8000000e-01, -8.7000000e-01, -8.6000000e-01, -8.5000000e-01, -8.4000000e-01, -8.3000000e-01, -8.2000000e-01, -8.1000000e-01, -8.0000000e-01, -7.9000000e-01, -7.8000000e-01, -7.7000000e-01, -7.6000000e-01, -7.5000000e-01, -7.4000000e-01, -7.3000000e-01, -7.2000000e-01, -7.1000000e-01, -7.0000000e-01, -6.9000000e-01, -6.8000000e-01, -6.7000000e-01, -6.6000000e-01, -6.5000000e-01, -6.4000000e-01, -6.3000000e-01, -6.2000000e-01, -6.1000000e-01, -6.0000000e-01, -5.9000000e-01, -5.8000000e-01, -5.7000000e-01, -5.6000000e-01, -5.5000000e-01, -5.4000000e-01, -5.3000000e-01, -5.2000000e-01, -5.1000000e-01, -5.0000000e-01, -4.9000000e-01, -4.8000000e-01, -4.7000000e-01, -4.6000000e-01, -4.5000000e-01, -4.4000000e-01, -4.3000000e-01, -4.2000000e-01, -4.1000000e-01, -4.0000000e-01, -3.9000000e-01, -3.8000000e-01, -3.7000000e-01, -3.6000000e-01, -3.5000000e-01, -3.4000000e-01, -3.3000000e-01, -3.2000000e-01, -3.1000000e-01, -3.0000000e-01, -2.9000000e-01, -2.8000000e-01, -2.7000000e-01, -2.6000000e-01, -2.5000000e-01, -2.4000000e-01, -2.3000000e-01, -2.2000000e-01, -2.1000000e-01, -2.0000000e-01, -1.9000000e-01, -1.8000000e-01, -1.7000000e-01, -1.6000000e-01, -1.5000000e-01, -1.4000000e-01, -1.3000000e-01, -1.2000000e-01, -1.1000000e-01, -1.0000000e-01, -9.0000000e-02, -8.0000000e-02, -7.0000000e-02, -6.0000000e-02, -5.0000000e-02, -4.0000000e-02, -3.0000000e-02, -2.0000000e-02, -1.0000000e-02, -1.0658141e-13, 1.0000000e-02, 2.0000000e-02, 3.0000000e-02, 4.0000000e-02, 5.0000000e-02, 6.0000000e-02, 7.0000000e-02, 8.0000000e-02, 9.0000000e-02, 1.0000000e-01, 1.1000000e-01, 1.2000000e-01, 1.3000000e-01, 1.4000000e-01, 1.5000000e-01, 1.6000000e-01, 1.7000000e-01, 1.8000000e-01, 1.9000000e-01, 2.0000000e-01, 2.1000000e-01, 2.2000000e-01, 2.3000000e-01, 2.4000000e-01, 2.5000000e-01, 2.6000000e-01, 2.7000000e-01, 2.8000000e-01, 2.9000000e-01, 3.0000000e-01, 3.1000000e-01, 3.2000000e-01, 3.3000000e-01, 3.4000000e-01, 3.5000000e-01, 3.6000000e-01, 3.7000000e-01, 3.8000000e-01, 3.9000000e-01, 4.0000000e-01, 4.1000000e-01, 4.2000000e-01, 4.3000000e-01, 4.4000000e-01, 4.5000000e-01, 4.6000000e-01, 4.7000000e-01, 4.8000000e-01, 4.9000000e-01, 5.0000000e-01, 5.1000000e-01, 5.2000000e-01, 5.3000000e-01, 5.4000000e-01, 5.5000000e-01, 5.6000000e-01, 5.7000000e-01, 5.8000000e-01, 5.9000000e-01, 6.0000000e-01, 6.1000000e-01, 6.2000000e-01, 6.3000000e-01, 6.4000000e-01, 6.5000000e-01, 6.6000000e-01, 6.7000000e-01, 6.8000000e-01, 6.9000000e-01, 7.0000000e-01, 7.1000000e-01, 7.2000000e-01, 7.3000000e-01, 7.4000000e-01, 7.5000000e-01, 7.6000000e-01, 7.7000000e-01, 7.8000000e-01, 7.9000000e-01, 8.0000000e-01, 8.1000000e-01, 8.2000000e-01, 8.3000000e-01, 8.4000000e-01, 8.5000000e-01, 8.6000000e-01, 8.7000000e-01, 8.8000000e-01, 8.9000000e-01, 9.0000000e-01, 9.1000000e-01, 9.2000000e-01, 9.3000000e-01, 9.4000000e-01, 9.5000000e-01, 9.6000000e-01, 9.7000000e-01, 9.8000000e-01, 9.9000000e-01, 1.0000000e+00, 1.0100000e+00, 1.0200000e+00, 1.0300000e+00, 1.0400000e+00, 1.0500000e+00, 1.0600000e+00, 1.0700000e+00, 1.0800000e+00, 1.0900000e+00, 1.1000000e+00, 1.1100000e+00, 1.1200000e+00, 1.1300000e+00, 1.1400000e+00, 1.1500000e+00, 1.1600000e+00, 1.1700000e+00, 1.1800000e+00, 1.1900000e+00, 1.2000000e+00, 1.2100000e+00, 1.2200000e+00, 1.2300000e+00, 1.2400000e+00, 1.2500000e+00, 1.2600000e+00, 1.2700000e+00, 1.2800000e+00, 1.2900000e+00, 1.3000000e+00, 1.3100000e+00, 1.3200000e+00, 1.3300000e+00, 1.3400000e+00, 1.3500000e+00, 1.3600000e+00, 1.3700000e+00, 1.3800000e+00, 1.3900000e+00, 1.4000000e+00, 1.4100000e+00, 1.4200000e+00, 1.4300000e+00, 1.4400000e+00, 1.4500000e+00, 1.4600000e+00, 1.4700000e+00, 1.4800000e+00, 1.4900000e+00, 1.5000000e+00, 1.5100000e+00, 1.5200000e+00, 1.5300000e+00, 1.5400000e+00, 1.5500000e+00, 1.5600000e+00, 1.5700000e+00, 1.5800000e+00, 1.5900000e+00, 1.6000000e+00, 1.6100000e+00, 1.6200000e+00, 1.6300000e+00, 1.6400000e+00, 1.6500000e+00, 1.6600000e+00, 1.6700000e+00, 1.6800000e+00, 1.6900000e+00, 1.7000000e+00, 1.7100000e+00, 1.7200000e+00, 1.7300000e+00, 1.7400000e+00, 1.7500000e+00, 1.7600000e+00, 1.7700000e+00, 1.7800000e+00, 1.7900000e+00, 1.8000000e+00, 1.8100000e+00, 1.8200000e+00, 1.8300000e+00, 1.8400000e+00, 1.8500000e+00, 1.8600000e+00, 1.8700000e+00, 1.8800000e+00, 1.8900000e+00, 1.9000000e+00, 1.9100000e+00, 1.9200000e+00, 1.9300000e+00, 1.9400000e+00, 1.9500000e+00, 1.9600000e+00, 1.9700000e+00, 1.9800000e+00, 1.9900000e+00, 2.0000000e+00, 2.0100000e+00, 2.0200000e+00, 2.0300000e+00, 2.0400000e+00, 2.0500000e+00, 2.0600000e+00, 2.0700000e+00, 2.0800000e+00, 2.0900000e+00, 2.1000000e+00, 2.1100000e+00, 2.1200000e+00, 2.1300000e+00, 2.1400000e+00, 2.1500000e+00, 2.1600000e+00, 2.1700000e+00, 2.1800000e+00, 2.1900000e+00, 2.2000000e+00, 2.2100000e+00, 2.2200000e+00, 2.2300000e+00, 2.2400000e+00, 2.2500000e+00, 2.2600000e+00, 2.2700000e+00, 2.2800000e+00, 2.2900000e+00, 2.3000000e+00, 2.3100000e+00, 2.3200000e+00, 2.3300000e+00, 2.3400000e+00, 2.3500000e+00, 2.3600000e+00, 2.3700000e+00, 2.3800000e+00, 2.3900000e+00, 2.4000000e+00, 2.4100000e+00, 2.4200000e+00, 2.4300000e+00, 2.4400000e+00, 2.4500000e+00, 2.4600000e+00, 2.4700000e+00, 2.4800000e+00, 2.4900000e+00, 2.5000000e+00, 2.5100000e+00, 2.5200000e+00, 2.5300000e+00, 2.5400000e+00, 2.5500000e+00, 2.5600000e+00, 2.5700000e+00, 2.5800000e+00, 2.5900000e+00, 2.6000000e+00, 2.6100000e+00, 2.6200000e+00, 2.6300000e+00, 2.6400000e+00, 2.6500000e+00, 2.6600000e+00, 2.6700000e+00, 2.6800000e+00, 2.6900000e+00, 2.7000000e+00, 2.7100000e+00, 2.7200000e+00, 2.7300000e+00, 2.7400000e+00, 2.7500000e+00, 2.7600000e+00, 2.7700000e+00, 2.7800000e+00, 2.7900000e+00, 2.8000000e+00, 2.8100000e+00, 2.8200000e+00, 2.8300000e+00, 2.8400000e+00, 2.8500000e+00, 2.8600000e+00, 2.8700000e+00, 2.8800000e+00, 2.8900000e+00, 2.9000000e+00, 2.9100000e+00, 2.9200000e+00, 2.9300000e+00, 2.9400000e+00, 2.9500000e+00, 2.9600000e+00, 2.9700000e+00, 2.9800000e+00, 2.9900000e+00, 3.0000000e+00, 3.0100000e+00, 3.0200000e+00, 3.0300000e+00, 3.0400000e+00, 3.0500000e+00, 3.0600000e+00, 3.0700000e+00, 3.0800000e+00, 3.0900000e+00, 3.1000000e+00, 3.1100000e+00, 3.1200000e+00, 3.1300000e+00, 3.1400000e+00, 3.1500000e+00, 3.1600000e+00, 3.1700000e+00, 3.1800000e+00, 3.1900000e+00, 3.2000000e+00, 3.2100000e+00, 3.2200000e+00, 3.2300000e+00, 3.2400000e+00, 3.2500000e+00, 3.2600000e+00, 3.2700000e+00, 3.2800000e+00, 3.2900000e+00, 3.3000000e+00, 3.3100000e+00, 3.3200000e+00, 3.3300000e+00, 3.3400000e+00, 3.3500000e+00, 3.3600000e+00, 3.3700000e+00, 3.3800000e+00, 3.3900000e+00, 3.4000000e+00, 3.4100000e+00, 3.4200000e+00, 3.4300000e+00, 3.4400000e+00, 3.4500000e+00, 3.4600000e+00, 3.4700000e+00, 3.4800000e+00, 3.4900000e+00, 3.5000000e+00, 3.5100000e+00, 3.5200000e+00, 3.5300000e+00, 3.5400000e+00, 3.5500000e+00, 3.5600000e+00, 3.5700000e+00, 3.5800000e+00, 3.5900000e+00, 3.6000000e+00, 3.6100000e+00, 3.6200000e+00, 3.6300000e+00, 3.6400000e+00, 3.6500000e+00, 3.6600000e+00, 3.6700000e+00, 3.6800000e+00, 3.6900000e+00, 3.7000000e+00, 3.7100000e+00, 3.7200000e+00, 3.7300000e+00, 3.7400000e+00, 3.7500000e+00, 3.7600000e+00, 3.7700000e+00, 3.7800000e+00, 3.7900000e+00, 3.8000000e+00, 3.8100000e+00, 3.8200000e+00, 3.8300000e+00, 3.8400000e+00, 3.8500000e+00, 3.8600000e+00, 3.8700000e+00, 3.8800000e+00, 3.8900000e+00, 3.9000000e+00, 3.9100000e+00, 3.9200000e+00, 3.9300000e+00, 3.9400000e+00, 3.9500000e+00, 3.9600000e+00, 3.9700000e+00, 3.9800000e+00, 3.9900000e+00, 4.0000000e+00, 4.0100000e+00, 4.0200000e+00, 4.0300000e+00, 4.0400000e+00, 4.0500000e+00, 4.0600000e+00, 4.0700000e+00, 4.0800000e+00, 4.0900000e+00, 4.1000000e+00, 4.1100000e+00, 4.1200000e+00, 4.1300000e+00, 4.1400000e+00, 4.1500000e+00, 4.1600000e+00, 4.1700000e+00, 4.1800000e+00, 4.1900000e+00, 4.2000000e+00, 4.2100000e+00, 4.2200000e+00, 4.2300000e+00, 4.2400000e+00, 4.2500000e+00, 4.2600000e+00, 4.2700000e+00, 4.2800000e+00, 4.2900000e+00, 4.3000000e+00, 4.3100000e+00, 4.3200000e+00, 4.3300000e+00, 4.3400000e+00, 4.3500000e+00, 4.3600000e+00, 4.3700000e+00, 4.3800000e+00, 4.3900000e+00, 4.4000000e+00, 4.4100000e+00, 4.4200000e+00, 4.4300000e+00, 4.4400000e+00, 4.4500000e+00, 4.4600000e+00, 4.4700000e+00, 4.4800000e+00, 4.4900000e+00, 4.5000000e+00, 4.5100000e+00, 4.5200000e+00, 4.5300000e+00, 4.5400000e+00, 4.5500000e+00, 4.5600000e+00, 4.5700000e+00, 4.5800000e+00, 4.5900000e+00, 4.6000000e+00, 4.6100000e+00, 4.6200000e+00, 4.6300000e+00, 4.6400000e+00, 4.6500000e+00, 4.6600000e+00, 4.6700000e+00, 4.6800000e+00, 4.6900000e+00, 4.7000000e+00, 4.7100000e+00, 4.7200000e+00, 4.7300000e+00, 4.7400000e+00, 4.7500000e+00, 4.7600000e+00, 4.7700000e+00, 4.7800000e+00, 4.7900000e+00, 4.8000000e+00, 4.8100000e+00, 4.8200000e+00, 4.8300000e+00, 4.8400000e+00, 4.8500000e+00, 4.8600000e+00, 4.8700000e+00, 4.8800000e+00, 4.8900000e+00, 4.9000000e+00, 4.9100000e+00, 4.9200000e+00, 4.9300000e+00, 4.9400000e+00, 4.9500000e+00, 4.9600000e+00, 4.9700000e+00, 4.9800000e+00, 4.9900000e+00]) array([[-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], ..., [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99], [-5. , -4.99, -4.98, ..., 4.97, 4.98, 4.99]]) (1000, 1000) (1000,) array([[-5. , -5. , -5. , ..., -5. , -5. , -5. ], [-4.99, -4.99, -4.99, ..., -4.99, -4.99, -4.99], [-4.98, -4.98, -4.98, ..., -4.98, -4.98, -4.98], ..., [ 4.97, 4.97, 4.97, ..., 4.97, 4.97, 4.97], [ 4.98, 4.98, 4.98, ..., 4.98, 4.98, 4.98], [ 4.99, 4.99, 4.99, ..., 4.99, 4.99, 4.99]]) (1000, 1000) array([[7.07106781, 7.06400028, 7.05693985, ..., 7.04988652, 7.05693985, 7.06400028], [7.06400028, 7.05692568, 7.04985815, ..., 7.04279774, 7.04985815, 7.05692568], [7.05693985, 7.04985815, 7.04278354, ..., 7.03571603, 7.04278354, 7.04985815], ..., [7.04988652, 7.04279774, 7.03571603, ..., 7.0286414 , 7.03571603, 7.04279774], [7.05693985, 7.04985815, 7.04278354, ..., 7.03571603, 7.04278354, 7.04985815], [7.06400028, 7.05692568, 7.04985815, ..., 7.04279774, 7.04985815, 7.05692568]]) 将条件逻辑作为数组操作 numpy.where函数是三元表达式x if condition else y的向量化版本 array([1.1, 2.2, 1.3, 1.4, 2.5]) np.where的第二个和第三个参数并不需要是数组, 它们可以是标量. where在数据分析中的典型用法是根据一个数组来生成另一个数组. array([[-0.33542071, 1.21930406, -0.09681939, -0.82459791], [-1.55407736, -0.21346076, 0.67139561, -0.5072354 ], [-0.65982433, 0.49432098, 2.94458873, -0.92224973], [-0.39890308, 0.31417223, -1.18291276, -0.06984539]]) array([[False, True, False, False], [False, False, True, False], [False, True, True, False], [False, True, False, False]]) array([[-2, 2, -2, -2], [-2, -2, 2, -2], [-2, 2, 2, -2], [-2, 2, -2, -2]]) np.where将标量和数组联合 array([[-0.33542071, 2. , -0.09681939, -0.82459791], [-1.55407736, -0.21346076, 2. , -0.5072354 ], [-0.65982433, 2. , 2. , -0.92224973], [-0.39890308, 2. , -1.18291276, -0.06984539]]) 传递给数组既可以是同等大小的数组, 也可以是标量 数学和统计方法 array([[-1.04219602, 0.49935139, 0.4915034 , 1.20546698], [ 1.31174433, -0.51520489, -0.77213118, 0.01633843], [ 0.86525923, 0.14926574, -2.0697 , -0.40784359], [ 0.67473966, 0.77374834, 0.81528238, 1.29309864], [-0.42572447, -0.09111319, 0.06267313, 0.72916931]]) 0.1781863823308411 0.1781863823308411 3.563727646616822 像mean、sum等函数可以接收一个可选参数axis, 这个参数可以用来计算给定轴向上的统计值, 形成一个下降一维度的数组 array([ 0.28853144, 0.01018667, -0.36575466, 0.88921726, 0.0687512 ]) array([ 0.27676455, 0.16320948, -0.29447445, 0.56724596]) array([ 0, 1, 3, 6, 10, 15, 21, 28]) array([[0, 1, 2], [3, 4, 5], [6, 7, 8]]) array([[ 0, 1, 2], [ 3, 5, 7], [ 9, 12, 15]]) array([[ 0, 0, 0], [ 3, 12, 60], [ 6, 42, 336]]) 布尔值数组的方法 48 两个非常有用的方法any和all True False 排序 array([ 3.71501338, -0.14777101, -0.12295073, -0.72093906, 0.7119684 , 0.26384242]) array([-0.72093906, -0.14777101, -0.12295073, 0.26384242, 0.7119684 , 3.71501338]) array([[ 0.55589846, -0.14870632, -0.34138091], [-0.1364057 , 2.80339281, 1.85958005], [ 0.54255931, 0.1986565 , -0.03543301], [ 0.71778153, -1.72824714, -0.4782502 ], [ 0.5793238 , -0.98756225, -1.1007428 ]]) array([[-0.34138091, -0.14870632, 0.55589846], [-0.1364057 , 1.85958005, 2.80339281], [-0.03543301, 0.1986565 , 0.54255931], [-1.72824714, -0.4782502 , 0.71778153], [-1.1007428 , -0.98756225, 0.5793238 ]]) array([[-1.72824714, -0.98756225, 0.54255931], [-1.1007428 , -0.4782502 , 0.55589846], [-0.34138091, -0.14870632, 0.5793238 ], [-0.1364057 , 0.1986565 , 0.71778153], [-0.03543301, 1.85958005, 2.80339281]]) 唯一值 array([&#39;Bob&#39;, &#39;Joe&#39;, &#39;Will&#39;], dtype=&#39;&lt;U4&#39;) array([1, 2, 3, 4]) 另一个函数, np.in1d, 可以检查一个数组中的值是否在另一个数组中, 并返回一个布尔值数组 array([ True, False, False, True, True, False, True]) 线性代数 array([[1., 2., 3.], [4., 5., 6.]]) array([[ 6., 23.], [-1., 7.], [ 8., 9.]]) array([[ 28., 64.], [ 67., 181.]]) 特殊符号@也作为中缀操作数, 用于点乘矩阵操作: array([ 6., 15.]) numpy.linalg拥有一个矩阵分解的标准函数库, 以及其他常用函数 array([[ 13.08899259, 6.60945965, -12.15869037, 12.90204945, 21.53272491], [ 6.60945965, 3.55276522, -6.18323752, 6.52950993, 10.90028303], [-12.15869037, -6.18323752, 12.14766636, -12.89675877, -20.55964471], [ 12.90204945, 6.52950993, -12.89675877, 14.04116086, 21.81219411], [ 21.53272491, 10.90028303, -20.55964471, 21.81219411, 36.19051174]]) array([[ 1.00000000e+00, -1.25391264e-15, -8.48159041e-15, 2.15518628e-15, -3.69683867e-15], [ 2.53043695e-15, 1.00000000e+00, 6.17971746e-16, -4.15969200e-15, -5.27877362e-15], [ 5.90223907e-15, 4.33710022e-15, 1.00000000e+00, 1.83046671e-14, 7.16678788e-15], [ 3.00131691e-15, 6.66844034e-15, -1.17452191e-14, 1.00000000e+00, 1.31770745e-14], [-1.41356944e-15, -2.30585695e-15, 4.37926092e-15, -3.52351374e-15, 1.00000000e+00]]) array([[-5.9541469 , 3.67886054, 2.86032036, 1.02910728, 3.45127662], [ 0. , -3.83458562, -0.17887336, -0.63293168, 1.44614429], [ 0. , 0. , -6.22122868, -4.0027883 , -1.12406318], [ 0. , 0. , 0. , -1.12808648, 0.69115622], [ 0. , 0. , 0. , 0. , 0.01892969]]) 伪随机数生成 使用normal生成一个\(4\times4\)的正态分布 array([[-0.97816398, -1.94346808, -0.92198709, 1.29764573], [ 1.00294208, -0.74529224, 0.43978217, 1.00792921], [-0.11337431, -0.03736872, 0.33455556, -0.73974292], [ 0.48545596, -0.53500461, -0.18658909, 1.19422892]]) 可以通过np.random.seed更改Numpy的随机种子: numpy.random中的数据生成函数公用了一个全局的随机数种子. 为了避免全局状态, 可以使用numpy.random.RandomState生成一个随机数生成器, 使其数据独立于其他的随机数状态: --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-70-89cb88b73812&gt; in &lt;module&gt;() ----&gt; 1 rng.random(10) AttributeError: &#39;mtrand.RandomState&#39; object has no attribute &#39;random&#39; array([ 0.47143516, -1.19097569, 1.43270697, -0.3126519 , -0.72058873, 0.88716294, 0.85958841, -0.6365235 , 0.01569637, -2.24268495])]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>数据分析基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Numpy基础(一)]]></title>
    <url>%2F2018%2F09%2F16%2FNumpy%E5%9F%BA%E7%A1%80-%E4%B8%80%2F</url>
    <content type="text"><![CDATA[Numpy的ndarray: 一种多维数组对象 array([[-0.27145581, 0.20453947, 1.20194872], [-0.02400358, 0.24259435, -0.65364157]]) array([[-2.71455807, 2.04539469, 12.01948724], [-0.24003576, 2.4259435 , -6.53641571]]) array([[-0.54291161, 0.40907894, 2.40389745], [-0.04800715, 0.4851887 , -1.30728314]]) (2, 3) dtype(&#39;float64&#39;) 创建ndarray 创建数组最简单的办法就是使用array函数. 它接受一切序列型的对象(包括其他数组), 然后产生一个新的含有传入数据的Numpy数组 array([6. , 7.5, 8. , 0. , 1. ]) array([[1, 2, 3, 4], [5, 6, 7, 8]]) 2 (2, 4) np.array会自动推断生成数组的数据类型 dtype(&#39;float64&#39;) dtype(&#39;int64&#39;) array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]) array([[0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0.], [0., 0., 0., 0., 0., 0.]]) array([[[1.74618620e-076, 3.97062373e+246], [1.16318408e-028, 2.21471564e+160], [2.59982058e-056, 3.59853464e+179]], [[5.93300900e-038, 5.04621361e+180], [8.37170571e-144, 1.01849500e+248], [1.16096643e-028, 5.30581644e+180]]]) array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]) array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]) array默认复制所有输入数据; asarray, 如果输入已经是ndarray, 则不再复制 array([1, 2, 3]) array([[1., 0.], [0., 1.]]) array([[0, 0, 0, 0], [0, 0, 0, 0]]) ndarray的数据类型 dtype(&#39;float64&#39;) dtype(&#39;int32&#39;) 转换数组的数据类型 dtype(&#39;int64&#39;) dtype(&#39;float64&#39;) 在本例中, 整数被转换成了浮点数.如果浮点数转换成整数, 则小数部分将会被截取删除 array([ 3.7, -1.2, -2.6, 0.5, 12.9, 10.1]) array([ 3, -1, -2, 0, 12, 10], dtype=int32) 如果某字符串数组表示全是数字, 也可以用astype将其转换成数值形式 array([b&#39;1.25&#39;, b&#39;-9.6&#39;, b&#39;42&#39;], dtype=&#39;|S4&#39;) array([ 1.25, -9.6 , 42. ]) array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.]) array([112, 111, 114, 97, 114, 105, 108, 121], dtype=uint32) 使用astype时总是生成一个新的数组 Numpy数组的运算 array([[1., 2., 3.], [4., 5., 6.]]) array([[ 1., 4., 9.], [16., 25., 36.]]) array([[0., 0., 0.], [0., 0., 0.]]) array([[1. , 0.5 , 0.33333333], [0.25 , 0.2 , 0.16666667]]) array([[1. , 1.41421356, 1.73205081], [2. , 2.23606798, 2.44948974]]) array([[ 0., 4., 1.], [ 7., 2., 12.]]) array([[False, True, False], [ True, False, True]]) 不同大小的数组之间的运算叫做广播 基本的索引和切片 array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]) 5 array([5, 6, 7]) array([ 0, 1, 2, 3, 4, 12, 12, 12, 8, 9]) 如上所示, 当你将标量值赋值给一个切片时, 该值会自动传播到整个选区.跟列表最重要的区别在于, 数组切片是原始数组的视图. 这意味着数据不会被复制, 视图上的任何修改都会直接反映到原数组上. array([12, 12, 12]) 当改变arr_slice, 变化也会体现在原数组上 array([ 0, 1, 2, 3, 4, 12, 12345, 12, 8, 9]) array([ 0, 1, 2, 3, 4, 64, 64, 64, 8, 9]) 如果你想要得到的是ndarry切片的一份副本而非视图, 就需要明确地进行复制操作, 例如arr[5:8].copy() array([7, 8, 9]) 3 3 轴0作为行, 轴1作为列 array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]]) array([[1, 2, 3], [4, 5, 6]]) 标量和数组都可以传递给arr3d[0]: array([[[42, 42, 42], [42, 42, 42]], [[ 7, 8, 9], [10, 11, 12]]]) array([[[ 1, 2, 3], [ 4, 5, 6]], [[ 7, 8, 9], [10, 11, 12]]]) array([7, 8, 9]) array([[ 7, 8, 9], [10, 11, 12]]) array([7, 8, 9]) 在上面所有这些选取数组子集的例子中, 返回的数组都是视图 布尔索引 array([&#39;Bob&#39;, &#39;Joe&#39;, &#39;Will&#39;, &#39;Bob&#39;, &#39;Will&#39;, &#39;Joe&#39;, &#39;Joe&#39;], dtype=&#39;&lt;U4&#39;) array([[ 0.33750495, 0.87858221, -1.17761082, 2.34847091], [-0.13196555, 0.52047032, 0.4773208 , 0.23596828], [ 1.3720038 , -0.70659583, -0.23109342, -0.12345765], [-0.34662676, -0.33928776, -1.42790341, 0.84134272], [-0.15224377, -1.1089024 , -0.97038997, 0.56403746], [-0.25892721, -0.60506496, 1.86708232, 0.132893 ], [ 0.45939055, -0.28324557, 2.50077175, -0.22691978]]) array([ True, False, False, True, False, False, False]) array([[ 0.33750495, 0.87858221, -1.17761082, 2.34847091], [-0.34662676, -0.33928776, -1.42790341, 0.84134272]]) array([[-1.17761082, 2.34847091], [-1.42790341, 0.84134272]]) array([2.34847091, 0.84134272]) array([False, True, True, False, True, True, True]) array([[-0.13196555, 0.52047032, 0.4773208 , 0.23596828], [ 1.3720038 , -0.70659583, -0.23109342, -0.12345765], [-0.15224377, -1.1089024 , -0.97038997, 0.56403746], [-0.25892721, -0.60506496, 1.86708232, 0.132893 ], [ 0.45939055, -0.28324557, 2.50077175, -0.22691978]]) array([[-0.13196555, 0.52047032, 0.4773208 , 0.23596828], [ 1.3720038 , -0.70659583, -0.23109342, -0.12345765], [-0.15224377, -1.1089024 , -0.97038997, 0.56403746], [-0.25892721, -0.60506496, 1.86708232, 0.132893 ], [ 0.45939055, -0.28324557, 2.50077175, -0.22691978]]) array([[ 0.33750495, 0.87858221, -1.17761082, 2.34847091], [-0.34662676, -0.33928776, -1.42790341, 0.84134272]]) 使用布尔值索引数据时, 总是生成数据的拷贝, 即使返回的数组并没有任何变化 Python的关键字and和or对布尔值数组并没有用, 请使用&amp;和|代替 array([[0.33750495, 0.87858221, 0. , 2.34847091], [0. , 0.52047032, 0.4773208 , 0.23596828], [1.3720038 , 0. , 0. , 0. ], [0. , 0. , 0. , 0.84134272], [0. , 0. , 0. , 0.56403746], [0. , 0. , 1.86708232, 0.132893 ], [0.45939055, 0. , 2.50077175, 0. ]]) array([[7. , 7. , 7. , 7. ], [0. , 0.52047032, 0.4773208 , 0.23596828], [7. , 7. , 7. , 7. ], [7. , 7. , 7. , 7. ], [7. , 7. , 7. , 7. ], [0. , 0. , 1.86708232, 0.132893 ], [0.45939055, 0. , 2.50077175, 0. ]]) 神奇索引 array([[0., 0., 0., 0.], [1., 1., 1., 1.], [2., 2., 2., 2.], [3., 3., 3., 3.], [4., 4., 4., 4.], [5., 5., 5., 5.], [6., 6., 6., 6.], [7., 7., 7., 7.]]) 为了选出一个符合特定顺序的子集, 可以通过传递一个包含指明所需顺序的列表或数组来完成 array([[4., 4., 4., 4.], [3., 3., 3., 3.], [0., 0., 0., 0.], [6., 6., 6., 6.]]) array([[5., 5., 5., 5.], [3., 3., 3., 3.], [1., 1., 1., 1.]]) array([[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23], [24, 25, 26, 27], [28, 29, 30, 31]]) array([ 4, 23, 29, 10]) array([[ 4, 7, 5, 6], [20, 23, 21, 22], [28, 31, 29, 30], [ 8, 11, 9, 10]]) 神奇索引和切片不同, 它总是将数据复制到一个新的数组中 数组转置和换轴 array([[ 0, 1, 2, 3, 4], [ 5, 6, 7, 8, 9], [10, 11, 12, 13, 14]]) array([[ 0, 5, 10], [ 1, 6, 11], [ 2, 7, 12], [ 3, 8, 13], [ 4, 9, 14]]) array([[-0.34408898, -1.37979923, -1.31569516], [ 0.4300182 , 0.53458254, 2.31329317], [ 0.91202655, -0.8713753 , 0.69748309], [ 1.80515511, -0.30402588, 0.59708737], [-0.72718466, 1.16915288, -1.35944484], [ 0.70524754, -0.82653288, -0.23491233]]) array([[ 7.34791663, -1.02712211, 2.08288264], [-1.02712211, 13.10926223, 3.60236728], [ 2.08288264, 3.60236728, 5.8434541 ]]) 换轴 对于高维数组, transpose需要用到一个由轴编号组成的元组, 才能进行转置 对多维数组来说, 确定最底层的一个基本元素位置需要用到的索引个数是维度. 这里可以理解为对shape返回元组的索引 array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7]], [[ 8, 9, 10, 11], [12, 13, 14, 15]]]) array([[[ 0, 1, 2, 3], [ 8, 9, 10, 11]], [[ 4, 5, 6, 7], [12, 13, 14, 15]]]) array([[[ 0, 4], [ 1, 5], [ 2, 6], [ 3, 7]], [[ 8, 12], [ 9, 13], [10, 14], [11, 15]]]) swapaxes返回的是数据的视图. 而没有对数据进行复制]]></content>
      <categories>
        <category>读书笔记</category>
      </categories>
      <tags>
        <tag>数据分析基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习基石 2.学习判断是与非]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%8E%9F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-2-%E5%AD%A6%E4%B9%A0%E5%88%A4%E6%96%AD%E6%98%AF%E4%B8%8E%E9%9D%9E%2F</url>
    <content type="text"><![CDATA[感知机假设集合 第一章里讲到机器学习的核心就是, 使用算法\(\mathcal{A}\)接受数据\(\mathcal{D}\), 从假设集合(所有可能性)\(\mathcal{H}\)中选出一个\(g\), 希望\(g \approx f\). 那么我们现在最关心的就是, \(\mathcal{H}\)应该是什么样的. 以之前提到的银行审核发放信用卡的场景为例, 假设我们把每个使用者定义为向量\(\bf x\), 包含\(d\)个维度, 例如\(x_1\)代表年龄, \(x_2\)代表年薪, 等等. 我们可以将这些维度综合起来给使用者一个整体的分数. 如果这个分数超过了某个标准, 那么就发放信用卡; 否则拒绝发放. 这样, 我们需要给每个\(x_i, i \in \{ 1, \ldots, d \}\)来赋一个系数\(w_i\), 如果特征对最后的影响是正面的, 那么就给\(w_i\)正值, 否则给负值. 如果我们在规定一个阈值\(\rm threshold\), 那么我们的决策方法就可以写成为, 如果\(\sum_{i=1}^d w_ix_i &gt; \rm threshold\), 就批准信用卡申请, 否则就拒绝. 我们可以进一步地规定输出空间\(\mathcal{Y} \in \{-1, +1\}\), 其中\(y=-1\)时表示拒绝, \(y=1\)时表示许可. 这样做的好处是我们可以直接使用\(\rm sign\)函数来求出\(y\)的值, 具体地说, 假设集合\(\mathcal{H}\)中的每个元素\(h \in \mathcal{H}\)都有如下形式 \[ h({\bf x}) ={\rm sign}((\sum_{i=1}^d w_ix_i) - {\rm threshold}) \] 其中\({\rm sign}\)函数的定义为 \[ {\rm sign}(x) = \begin{cases} +1 &amp; {\rm if \ } x&gt;0 \\ -1 &amp; {\rm if \ } x&lt;0 \end{cases} \] 即对用户的所有属性做一个加权打分, 看它是否超过阈值. 如果超过, 则批准; 否则就拒绝(如果正好等于阈值, 这种情况很少发生, 甚至可以随机决定\(y\)是\(-1\)还是\(1\)). 这里我们说\(\mathcal{H}\)是一个集合的原因是, 不同的\(\bf w\)和\(\rm threshold\)都对应了不同的\(h\), 所有这些可能性对应的所有\(h\)构成了最后的假设集合\(\mathcal{H}\). \(h\)这样的函数类型称为感知机(perceptron), 其中\(\bf w\)称为权重. 进一步地, 假设我们把\(-\rm threshold\)看做是\((-\rm threshold) \cdot (+1)\), 然后把\(+1\)看作是\(x_0\), 那么前面的公式形式可以进一步的简化, 即 \[ \begin{align*} h({\bf x}) &amp;= {\rm sign}((\sum_{i=1}^d w_ix_i) - {\rm threshold}) \\ &amp;= {\rm sign}((\sum_{i=1}^d w_ix_i)+\underbrace{(-{\rm threshold})}_{w_0}\cdot \underbrace{(+1)}_{x_0}) \\ &amp;= {\rm sign}(\sum_{i=0}^d w_ix_i) \\ &amp;= {\rm sign}({\bf w}^\mathsf{T}{\bf x}) \end{align*} \] 这里\(\bf w\)和\(\bf x\)都看作是列向量, 即维度为\((d+1)1\) 我们可以通过一个图例来加强理解. 假如我们顾客的特征数(也就是前面说的属性维度)为\(2\), 那么我们可以把任意输入\(\bf x\)画在一个平面\(\mathbb{R}^2\)上(类似的, 如果特征数为\(d\), 那么每个输入\(\bf x\)都可以在\(\mathbb{R}^d\)空间表示, 只是会对我们的可视化造成困难), 每个输入对应平面上的一个点. 这样, \(\mathbb{R}^2\)上的\(h\)都有如下形式: \[ h({\bf x}) = \rm sign(w_0+w_1x_1+w_2x_2) \] 可以看出, 每个\(h\)其实都对应了\(\mathbb{R}^2\)上的一条直线. 感知机规定位于直线某一侧的样本都被判定为正例, 另一侧的样本都被判定为负例. 不同的权重会产生不同的分类方式. 假设我们用蓝色的圈o表示正例, 红色的叉×表示负例, 下图给出了两个不同的感知机 1 2 可以看出来右边的感知机在训练集上效果更好, 因为它对所有例子做出了正确分类. 而左侧的感知机在训练集上表现稍逊(一个正例被误判为负, 两个负例被误判为正) 由于感知机都对应于一个超平面, 因此它也被称为是线性分类器(\(\mathbb R^2\)的超平面是一条直线, \(\mathbb R^3\)的超平面是一个平面, 以此类推). 感知机学习算法 在我们知道了\(h \in \mathcal H\)的形态以后, 接下来的问题是设计算法\(\mathcal A\)来选出最优的\(g\)来逼近理想的\(f\). 尽管我们不知道\(f\)具体应该是什么, 但是我们知道数据\(\mathcal D\)是由\(f\)生成的. 因此我们有理由相信, 好的\(g\)满足对所有我们已经收集道的数据, 其输出与\(f\)的输出尽可能接近, 即\(g({\bf x}_n) = f({\bf x}_n) = y_n\). 因此, 我们可以先找一个超平面, 至少能够对训练集中的数据正确分类. 然而难度在于, \(\mathcal H\)的大小通常都是无限的. 一种解决方案是, 我们可以先初始化一个超平面\(g_0\)(为了简单起见, 将其以其权重\({\bf w}_0\)代表, 称为初始权重). 我们允许这个超平面犯错, 但我们要设计算法, 让超平面遇到\(\mathcal D\)中的错分样本以后可以修正自己. 通常我们可以将\({\bf w}_0\)初始化为零向量\(\bf 0\). 然后, 在每一步\(t\), 找到一个使\({\bf w}_t\)错分的样本错分的样本\(({\bf x}_{n(t)}, y_{n(t)})\). 即有 \[ \rm sign({\bf w}^T_t {\bf x}_{n(t)}) \not= y_{n(t)} \] 接下里我们试着修正\({\bf w}_t\). 可以看到错分有两种情况: \(y\)本来应该是\(+1\), 但是模型判断出来是负值. 也就是说此时\(\bf w\)与\(\bf x\)之间的角度太大, 因此需要把\(\bf w\)往靠近\(\bf x\)的方向旋转使它们的角度变小. 可以通过让\({\bf w}_{t+1} \leftarrow {\bf w}_t + y_{n(t)} {\bf x}_{n(t)}\)达到这个目的 \(y\)本来应该是\(-1\), 但是模型判断出来是正值. 也就是说此时\(\bf w\)与\(\bf x\)之间的角度太小, 因此需要把\(\bf w\)往远离\(\bf x\)的方向旋转使它们的角度变大. 考虑到符号, 其实也可以通过让\({\bf w}_{t+1} \leftarrow {\bf w}_t + y_{n(t)} {\bf w}_{n(t)}\)达到这个目的 因此, 在\(t+1\)时刻, 我们总可以通过下式来修正\({\bf w}_t\), 即 \[ {\bf w}_{t+1} \leftarrow {\bf w}_t + y_{n(t)}{\bf x}_{n(t)} \] 3 4 感知机学习算法(Perceptron Learning Algorithm, PLA)就是重复上面的过程, 直到没有错误发生为止. 算法将最后得到的权重\(\bf w\)(记做\({\bf w}_{PLA}\))返回\(g\). 完整写法如下: 对于\(t = 0,1, \ldots\) 1). 找到一个使\({\bf w}_t\)错分的样本\(({\bf x}_{n(t)}, y_{n(t)})\). 即有 \[ sign({\bf w}_t^T {\bf x}_{n(t)}) \not = y_{n(t)} \] 2). 以如下方法修正\({\bf w}_t\): \[ {\bf w}_{t+1} \leftarrow {\bf w}_t + y_{n(t)}{\bf x}_{n(t)} \] 直到便利了所有样本一遍以后都没有找到错误为止. 由此, 也引出两个问题: 算法真的会停止吗? 能否确定算法返回的\(g \approx f\)? 感知机的有效性与确定终止性 回顾PLA算法的停止条件, 它是在没有找到错误的时候才停止, 这要求我们的数据可以用一条线将正例样本和负例样本分割开来(如果不存在这条线, PLA肯定是不可能停止的). 这种条件叫做线性可分条件. 接下来, 我们需要证明: 如果数据集的确是线性可分的, 感知机是否总是能找到一个超平面把数据恰好分开. 假设数据集\(\mathcal D\)线性可分, 我们先证明存在一个超平面\({\bf w}_f\)使得任意\(i \in \{1, \ldots, n\}\), \(y_i = {\rm sign}({\bf w}_f^T{\bf x}_i)\). 这意味着对每个\({\bf x}_i\), 它与超平面都有一定距离, 即 \[ \min_n y_n {\bf w}_f^\mathsf{T}{\bf x}_n &gt; 0 \] 其中\({\bf w}_f^T{\bf x}_n\)是点\({\bf w}_n\)到\({\bf w}_f\)的带符号的距离. 在训练过程中遇到的所有错分点\(({\bf x}_{n(t)}, y_{n(t)})\)(假设在时刻\(t\)遇到), 肯定有 \[ y_{n(t)}{\bf w}_f^\mathsf{T}{\bf x}_{n(t)} \ge \min_n y_n {\bf w}_f^\mathsf{T}{\bf x}_n &gt; 0 \] 我们可以先证明, \({\bf w}_t\)被\(({\bf x}_{n(t)}, y_{n(t)})\)纠正以后更加接近纠正以后更加接近\({\bf w}_f\). 我们可以通过两个向量的內积来判断它们是否接近: 两个向量越接近, 內积越大(可以理解为两个向量\(\bf u\)和和\(\bf v\)越接近, 其夹角, 那么\(\cos \theta\)越大, 所以两者的內积\({\bf u} \cdot {\bf v} = |\!|{\bf u}|\!||\!|{\bf v}|\!|\cos \theta\)越大), 则 \[ \begin{align*} {\bf w}_f^\mathsf{T}{\bf w}_{t+1} &amp;= {\bf w}_t^\mathsf{T}({\bf w}_t + y_{n(t)}{\bf x}_{n(t)}) \\ &amp;\ge {\bf w}_f^\mathsf{T}{\bf w}_t + \min_n y_n {\bf w}_f^\mathsf{T}{\bf x}_n \\ &amp;&gt; {\bf w}_f^\mathsf{T}{\bf w}_t + 0 = {\bf w}_f^\mathsf{T}{\bf w}_t\hspace{3ex} \blacksquare \end{align*} \] 但是这里又有一个新的问题, 即內积变大不一定说明两个向量接近, 因为向量长度变大也会导致內积变大. 因此接下来我们要证明, 修正\({\bf w}_t\)以后, 新的权重长度不会发生太大的变化. 这里要用到一个性质, 即\(PLA\)仅在遇到错误的数据时才更新权重, 即如果权重\({\bf w}_t\)被订正, 意味着\(sign({\bf w}_t^T{\bf w}_{n(t)}) \not = y_{n(t)}\), 也就是\(y_{n(t)}{\bf w}_t^T{\bf x}_{n(t)} \le 0\). 考虑到\(y_{n(t)}\)是标量, 且取值只可能为\(1\)或\(-1\)(即\(y_{n(t)}^2 = 1\)), \({\bf w}_t^T{\bf x}_{n(t)}\)也是标量, 因此 \[ \begin{align*} |\!|{\bf w}_{t+1}|\!|^2 &amp;= |\!|{\bf w}_t + y_{n(t)}{\bf x}_{n(t)}|\!|^2 \end{align*} \] 简记\(y = y_{n(t)}\), \({\bf x} = {\bf x}_{n(t)}\), \({\bf w} = {\bf w}_t\), 则 \[ \begin{align*} |\!|{\bf w}_{t+1}|\!|^2 &amp;= ({\bf w}+y{\bf x})^\mathsf{T}({\bf w}+y{\bf x}) \\ &amp;= {\bf w}^\mathsf{T}{\bf w} + 2y{\bf w}^\mathsf{T}{\bf x} + {\bf x}^\mathsf{T}{\bf x} \\ &amp;\le |\!|{\bf w}|\!|^2 + |\!|{\bf x}|\!|^2 \hspace{3ex}(\because y{\bf w}^\mathsf{T}{\bf x} \le 0) \\ &amp;\le |\!|{\bf w}|\!|^2 + \max_n|\!|{\bf x}_n|\!|^2 \end{align*} \] 即权重经过修正以后, 其长度最多增加\(\max_n |\!|{\bf x}_n|\!|^2\) 经由上面两部分, 假设权重的初始向量为\(\bf 0\), 我们可以求出经过\(T\)步更新最后得到的权重\({\bf w}_{T}\)与\(\bf w_{f}\)之间的夹角余弦值的下界. 为了求这个值, 只需要求两个权重归一化以后內积的下界即可, 即 \[ \inf \left(\frac{ {\bf w}_f^\mathsf{T}} {|\!|{\bf w}_f|\!|} \cdot \frac{{\bf w}_T}{|\!|{\bf w}_T|\!|} \right) \] 先看分子. 由于初始\({\bf w}_0 = {\bf 0}\), 因此由之前第一个证明的中间步骤, 我们可以写出第一次更新、第二次更新......后分子的下界, 即 \[ \begin{align*} {\bf w}_f^\mathsf{T}{\bf w}_1 &amp;\ge {\bf w}_f^\mathsf{T} \cdot {\bf 0} + \min_n y_n{\bf w}_f^\mathsf{T}{\bf x}_n \\ {\bf w}_f^\mathsf{T}{\bf w}_2 &amp;\ge {\bf w}_f^\mathsf{T}\cdot{\bf w}_1 + \min_n y_n{\bf w}_f^\mathsf{T}{\bf x}_n \ge {\bf x}_f^\mathsf{T} \cdot {\bf 0} + 2\min_n y_n{\bf w}_f^\mathsf{T}{\bf x}_n \\ &amp;\vdots \\ {\bf w}_f^\mathsf{T}{\bf w}_T &amp;\ge T \min_n y_n{\bf w}_f^\mathsf{T}{\bf x}_n \end{align*} \] 类似地, 对分母有 \[ |\!|{\bf w}_T|\!|^2 \le T\max_n|\!|{\bf x}_n|\!|^2 \] 因此, \[ \begin{align*} \frac{ {\bf w}_f^\mathsf{T}}{|\!|{\bf w}_f|\!|} \cdot \frac{ {\bf w}_T}{|\!|{\bf w}_T|\!|} &amp;\ge \frac{T\min_n y_n{\bf w}_f^\mathsf{T}{\bf x}_n}{|\!|{\bf w}_f|\!|\sqrt{T\max_n|\!|{\bf x}_n|\!|^2}} \\ &amp;= \sqrt{T}\cdot \frac{\min_n y_n{\bf w}_f^\mathsf{T}{\bf x}_n}{|\!|{\bf w}_f|\!|\sqrt{\max_n|\!|{\bf x}_n|\!|^2}} \end{align*} \] 按照Fun TIme中的记法, 记\(R^2 = \max_n |\!|{\bf x}_n|\!|^2, \rho = \min_n y_n \frac{{\bf w}_f^\mathsf{T}}{|\!|{\bf w}_f |\!|}{\bf x}_n\), 则 \[ \frac{ {\bf w}_f^\mathsf{T}}{|\!|{\bf w}_f|\!|} \cdot \frac{ {\bf w}_T}{|\!|{\bf w}_T|\!|} \ge \sqrt{T}\cdot\frac{\rho}{R} \] 由向量除以其长度得到的是单位向量, 长度为\(1\), 在这种情况下, 两者內积越大一定意味着两者夹角越小, 距离越近. 但是这里需要注意的是, 两者的距离不会无限接近, 到\(\cos \theta = 1\)时会停止, 因为两个单位向量的內积最大值为1, 因此从上面的不等式可推出 \[ \sqrt{T} \cdot \frac{\rho}{R} \le 1 \Rightarrow T \le \frac{R^2}{\rho^2} \] 即算法至多更新\(\frac{R^2}{\rho^2}\)步后一定会停止. 感知机在线性不可分数据上的应用 由上面的证明, 假设数据集是线性可分的, 那么\(PLA\)算法最后肯定会停止, 而且(对训练集)给出正确的分类. 该算法非常容易实现, 而且结束很快, 使用于任意\(\mathbb{R}^d\)空间. 但是这个算法最大的问题, 它提前假设训练集是训练可分的, 而且我们不知道算法什么时候会终止(因为上面给出的上限中用到了\({\bf w}_f\), 而我们不知道它是多少--甚至不知道是否存在!(在线性不可分的时候该向量不存在)) 那么我们来考虑一个最坏的情况, 即数据若的确是线性不可分的话, 应该如何应对. 由于数据产生的过程中可能会混入噪声, 这使得原本线性可分的数据也可能因为噪声的存在而不可分. 但是, 一般情况下, 噪声应该是一小部分, 即我们可以退而且其次, 不去寻找一个完美的超平面, 而是去寻找一个犯错误最少的超平面, 即 \[ {\bf w}_g \leftarrow \mathop{{\rm arg}\min}_{\bf w} \sum_{n=1}^N [\![ y_n \not = {\rm sign}({\bf w}^\mathsf{T}{\bf x}_n)]\!] \] 然而, 求解这个问题被证明是NP难的, 只能采用近似算法求解. 例如, 我们可以保存一个最好的权重, 该权重到目前为止错分的数量最少. 该算法被称为&quot;口袋法&quot;, 其完整细节如下: 设定初始权重\(\hat{\bf w}\) 对时刻\(t=0, 1, \cdots\) 随机寻找一个\({\bf w}_t\)错分的样本\(({\bf x}_{n(t)}, y_{n(t)})\) 试图通过如下方法修正\({\bf w}_t\) \[ {\bf w}_{t+1} \leftarrow {\bf w}_t + y_{n(t)}{\bf x}_{n(t)} \] 如果\({\bf w}_{t+1}\)犯的错误比\(\hat{\bf w}\)少, 那么将\(\hat{\bf w}\)替换为\({\bf w}_{t+1}\) 直到足够多次迭代完成. 我们将\(\hat{\bf w}\)(称为\({\bf w}_{pocket}\))返回为\(g\) 注意在线性可分集合上也可以使用口袋法, 算法也可以返回一个无训练误差的解. 但是由于每次更新权重以后, 都要在所有数据上使用新旧权重各跑一遍, 来计算错分数量, 因此口袋法的执行时间通常比原始\(PLA\)的计算时间长很多. +参考 txshi-mt.com/2017/08/01/NTUML-1-the-Learning-Problem/]]></content>
      <categories>
        <category>课程笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F09%2F09%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post More info: Writing Run server More info: Server Generate static files More info: Generating Deploy to remote sites More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[机器学习基石 1.学习问题]]></title>
    <url>%2F2018%2F09%2F09%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%9F%B3-1-%E5%AD%A6%E4%B9%A0%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[机器学习的概念 我们可以从人类的学习思维入手. 人类的学习过程, 是从观察出发, 经过大脑内化以后, 变成有用的技巧. 机器学习, 类似地, 是我们希望让计算机模拟人类的学习过程. 这时, 计算机观察到的东西被称作数据, 而思考过程实际上是计算过程, 技巧则是提高某一方面的表现. 因此, 机器学习的过程 为什么需要机器学习? 给定一张照片, 判断照片里的物体是不是一棵树. 使用传统的方法, 就需要对&quot;什么是树&quot;做出回答, 给出树的定义, 将其实现为程序. 按照规则进行判断, 并将其表述出来是很困难的. 然而, 一个小孩认识树的方法其实是通过观察, 经过经验的积累判断这个是树或者不是, 并不是教条的从长辈那里学习判断规则. 类似地, 我们可以让计算机自己从数据中学习树的判断方法. 因此, 机器学习是构建复杂系统的一种方法 机器学习的使用场景 当我们不能提前想好各种情况, 手工编码规则时. 例如让机器人在火星上导航, 我们不可能提前想到它在火星上会遇到什么样的情况 当我们无法轻易地定义问题的解决方案时. 例如要做语音识别/视觉识别, 我们无法对音频信号做出准确定义 当人们需要做出快速决策时. 例如高频交易 当要让机器服务于海量用户时. 例如做服务个性化定制 因此, 可以从以下三个关键点进行判断, 看是否适合使用机器学习 问题是&quot;可以学习的&quot;, 即存在一些潜在的模式, 以至于性能可以被提高 这些规则难以清晰定义 手里掌握对应的数据 机器学习的应用 机器学习在衣食住行四个方面都得到了广泛地应用 衣: Abu-Mostafa 2012利用销售数据和对用户的调研结果构建推荐系统给用户推荐穿搭 食: Sadilek et al. 2013利用机器学习, 根据Twitter数据, 来判断餐厅的好坏 住: Tsanas and Xifara 2012利用已有房间的特点和耗能, 预测房屋的能用消耗 此外还有两个领域: 教育和娱乐 教育: 系统根据学生的答题情况, 有针对地提供题目让学生练习其薄弱的部分, 同时将太难的题推后给出. 即, 给定一名学生的答题历史和一个题目, 预测学生是否能做对这道题( KDDCup 2010 ) 娱乐: 系统根据用户的历史打分, 预测用户对新电影的打分( KDDCup 2011 ) 机器学习的过程 问题背景 以银行信用卡发卡这一问题为例. 假设银行收集了一些用户的基本信息, 例如下表 特征 值 年龄 23 性别 女 所在地居住年数 1 工龄 0.5 负债额 200,000 银行要解决的问题是, 对于这样的客户, 是否应该给她发放信用卡 问题形式化描述 为了更加形式化地描述这个问题, 需要先定义一些符号: 输入: \({\bf x} \in \mathcal{X}\), 用户的特征 输出: \({\bf y} \in \mathcal{Y}\), 是否发放信用卡 目标函数: \(f: \mathcal{X} \rightarrow \mathcal{Y}\), 是我们期望学到, 但是目前不知道的东西. 是最理想的公式 数据: \(\mathcal{D} = \{({\bf x}_1, y_1), ({\bf x}_2, y_2), \ldots, ({\bf x}_n, y_n)}\), 是之前积累的记录 假设: \(g: \mathcal{X} \rightarrow \mathcal{Y}\), 是机器从数据中学到的函数. 我们通常都希望\(g\)的表现足够好, 即\(g \approx f\). 注意这里\(g\)不一定等于\(f\)(实际上, 我们永远也无法知道真正的\(f\)是什么样子, 只知道由\(f\)产生的数据\(\mathcal{D}\)) 机器学习算法: \(\mathcal {A}\), 是由\(\mathcal {D}\)产生\(g\)的算法, 可以理解为\(\mathcal {A}\)会从各种不同假设\(h_k\)(这里\(h_k\)有好有坏)构成的集合\(\mathcal{H}\)中挑选出来一个最好的\(g\), 使得\(g \approx f\). 即\(\mathcal{A}\)以\(\mathcal{D}\)和\(\mathcal{H}\)为输入, 以\(g\)为输出 机器学习过程 我们所讲的机器学习模型, 指的就是\(\mathcal{A}\)和\(\mathcal{H}\) 在有个这些记号以后, 我们可以重新给机器学习下一个定义 机器学习是使用数据计算假设\(g\)以逼近目标函数\(f\)的过程 机器学习与其它名词 机器学习与数据挖掘 数据挖掘的一个简单定义是使用海量数据, 在其中找出一些有趣的现象或性质. 这里, 如果&quot;有用的性质&quot;就是&quot;能够逼近目标函数的假设&quot;, 那么数据挖掘和机器学习是没有区别的. 如果&quot;有用的性质&quot;与&quot;假设&quot;是相关联的, 那么数据挖掘在很大程度上可以帮助机器学习 传统上的数据挖掘还关注如何在大的数据集中进行有效计算, 不过现在已经很难将机器学习和数据挖掘这两个概念分开了. 机器学习与人工智能 人工智能要求计算机呈现出一些智能的行为. 由于机器学习逼近目标函数的过程就展示了一些智能, 因此我们可以说, 机器学习是实现人工智能的一种手段. 机器学习与统计学 统计学是使用数据来对未知过程进行推论. 考虑到假设\(g\)是推论结果, \(f\)是不知道的事, 那么可以说统计是实现机器学习的一种方法. 但是传统的统计学从数学出发, 很多工具是为数学假设提供证明和推论. 而机器学习看重的是如何计算出结果. 总而言之, 统计学为机器学习提供了很多有力的工具 +参考 txshi-mt.com/2017/08/01/NTUML-1-the-Learning-Problem/]]></content>
      <categories>
        <category>课程笔记</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
</search>
